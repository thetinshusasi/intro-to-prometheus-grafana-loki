Promethus : Time series db for query, storing data
Amazon cloud watch : ?

Prometheus  web interface can be accessed using https only. Also grafana also checks for certificates

Exporter : Tool used by Prometheus to pull metrics from various services such as DBs , SQL, IOT device, HAProxy
            Eg Node exporters
Push Gateway : Tool used by backend apps to push metrics on to and then it will be pulled
                 by Prometheus in sometime

Node Exporter is an agent designed to collect hardware and operating system metrics from a server and
expose them in a format that Prometheus can understand. It's a key component in the Prometheus
monitoring ecosystem, acting as the bridge between your machine's low-level data and the Prometheus server.


How it Works âš™ï¸
The Prometheus server uses a pull-based model for monitoring, which means it actively requests metrics from its targets. Node Exporter serves as one of these targets. You install Node Exporter on each server you want to monitor. Once it's running, it exposes a /metrics endpoint, typically on port 9100.


When configured, the Prometheus server periodically scrapes this endpoint, collecting a wide range of metrics about the host machine.

Key Functions ğŸ“Š
Node Exporter provides a wealth of information about the host it's running on, including:

CPU usage: Tracks total CPU time, as well as time spent in various modes like user, system, and I/O wait.

Memory utilization: Provides details on available memory, free memory, and swap usage.

Disk I/O and space: Monitors disk reads and writes, as well as filesystem capacity and available space.

Network statistics: Collects metrics on network traffic, including bytes sent and received, packet errors, and connection states.

System metrics: Gathers information on system uptime, boot time, and process counts.

- Node Exporter can be extended with pluggable metrics collector




Install Node exporter (provided for linux env )
 wget https://github.com/prometheus/node_exporter/releases/download/v1.9.1/node_exporter-1.9.1.darwin-amd64.tar.gz

 Node exporter will run on 9100 port
 Health check link : http://localhost:9100/metrics


 Prometheus yml file is located in "/usr/local/etc"

 In Ubuntu, you create or run Node Exporter as a service . Coz if you run in terminal , it will die once you close the terminal


 Prmethus Model 
 - <Meteric Name> {key1=value1,key2=value2...}

 Prometheus Data types
  - Scalar : float ,string
  - Instant Vectors : An instant vector is a set of time series, each containing one sample (value) per series at a specific instant in time.
    Instant vectors are â€œsnapshotsâ€ of your system at a single moment in time (the query evaluation time).
    Eg up
    might return
    up{instance="web-1", job="api"}  1
    up{instance="web-2", job="api"}  0
    
        - common examples
            http_requests_total
            node_cpu_seconds_total
            memory_usage_bytes
  - A range vector is a set of time series where each series includes multiple data points over a time range.


  We have binary (< , == , >  etc) and arthematic operateor (+ ,- , /, * ,%,^)


Matcher and selectors

   1. A metric selector tells Prometheus which metric name and which series (labels) to fetch.

    Syntax:
    metric_name{label_matchers}
    
   2.  Matchers are conditions inside {} that filter which time series to include based on label names and values.

    Types of matchers:
        = exact match
        != not equal
        =~ regex match
        !~ regex not match

    Examples:
    node_cpu_seconds_total{mode="idle"}
    -> select CPU idle time across all nodes


Alerts in Prometheus
   they are usually kept at 10% of the point of chaos
   defined in Alerts Definition Yml file
   written in promql
   stored in prometheus server
   Need an alert manager to send notifications or emails in Promethus



Some Awesome Alert configs : https://samber.github.io/awesome-prometheus-alerts/rules#postgresql


Alert manager
 For mac system : we had to use Mac port to install alert managers. For some reason there wasn't a homebrew system is available


================================================================================
PROMETHEUS ALERTS, GROUPS, RULES & ALERTMANAGER - COMPREHENSIVE SUMMARY
================================================================================

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
1. ALERT GROUPS - WHAT THEY ARE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

What is a Group?
- A group is a logical container for related alert rules
- Helps organize alerts by category, priority, or service
- All rules in a group are evaluated together at the same time
- Each group can have its own evaluation interval (optional)

Structure:
  groups:
    - name: GroupName
      interval: 30s  # Optional: how often to evaluate this group
      rules:
        - alert: AlertName1
        - alert: AlertName2

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
2. MULTIPLE GROUPS & MULTIPLE RULES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Can You Have Multiple Groups?
âœ“ YES - You can have multiple groups in the same file or across multiple files

Can You Have Multiple Rules in a Group?
âœ“ YES - A group can contain multiple rules

Example:
  groups:
    - name: InfrastructureAlerts
      rules:
        - alert: NodeExporterDown
        - alert: HighCPUUsage
        - alert: DiskFull
    
    - name: ApplicationAlerts
      rules:
        - alert: ServiceDown
        - alert: HighLatency

Best Practices:
- Organize by category (Infrastructure, Application, System Resources)
- Use different intervals for different priorities
- Group related alerts together for easier management

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
3. HOW RULES WORK - INDEPENDENT EVALUATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Key Point: Rules are evaluated INDEPENDENTLY

What This Means:
- Each rule in a group is evaluated separately
- If one rule fires, it doesn't affect other rules
- Each rule creates its own alert when it fires
- Non-firing rules don't create alerts

Example Scenario:
  Group: SystemAlerts
    - NodeExporterDown: FIRES â†’ Creates alert â†’ Sent to Alertmanager
    - HighCPU: Doesn't fire â†’ No alert created
    - HighMemory: FIRES â†’ Creates alert â†’ Sent to Alertmanager

Result: Two separate alerts are sent to Alertmanager

Important:
- Rules in a group are only evaluated together (same time)
- But each rule operates independently
- Each firing rule creates its own alert
- Alertmanager receives each alert separately

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
4. ALERTMANAGER - GROUPING & NOTIFICATIONS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

How Alertmanager Groups Alerts:
- Alertmanager groups alerts by labels (like alertname, instance, severity)
- Default grouping: By 'alertname' only
- Grouping is controlled by 'group_by' setting in route configuration

Default Behavior:
  group_by: ['alertname']  # Default if not specified
  - All alerts with same alertname â†’ grouped together
  - Different alertnames â†’ separate groups

Custom Grouping Options:
  group_by: ['alertname', 'instance']  # Group by alertname AND instance
  group_by: ['severity']                # Group by severity only
  group_by: []                          # No grouping - one email per alert

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
5. EMAIL NOTIFICATIONS - HOW THEY WORK
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

How Many Emails Are Sent?
- Alertmanager sends ONE EMAIL per alert group (not per alert)
- Multiple alerts in the same group â†’ ONE email with all alerts listed
- Different groups â†’ separate emails

Example: 3 identical alerts arrive
  - NodeExporterDown (server1)
  - NodeExporterDown (server2)
  - NodeExporterDown (server3)

Result: 1 EMAIL containing all 3 alerts separately

What's in the Email?
- Subject: Shows alert name and count [FIRING:3] NodeExporterDown
- Group labels: Common labels that define the group
- Individual alerts: Each alert listed separately with:
  * All its labels (instance, severity, job, etc.)
  * All its annotations (summary, description)
  * The metric value
  * Timestamp

Email Format Example:
  Subject: [FIRING:3] NodeExporterDown
  
  Alert Group: {alertname="NodeExporterDown", severity="critical"}
  
  Alerts (3):
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Alert 1:
    Labels:
      - alertname: NodeExporterDown
      - instance: server1
      - severity: critical
    Annotations:
      - summary: Node Exporter is not running
      - description: Node Exporter is not running on server1
    Value: 0
  
  Alert 2:
    Labels:
      - alertname: NodeExporterDown
      - instance: server2
      ...
  
  Alert 3:
    Labels:
      - alertname: NodeExporterDown
      - instance: server3
      ...

Key Points:
âœ“ One email per group (not per alert)
âœ“ Each alert is listed separately with full details
âœ“ You can see which specific instances/servers are affected
âœ“ Subject shows count of alerts in the group

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
6. TIMING CONFIGURATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Alertmanager Route Timing Parameters:

group_wait: 10s
  - How long to wait before sending initial notification for a new group
  - If multiple alerts arrive within this time, they're grouped together
  
group_interval: 10s
  - How long to wait before sending a new notification about the same group
  - If new alerts join the group, wait this long before sending update
  
repeat_interval: 10m
  - How long to wait before repeating the same alert notification
  - Default is 4 hours if not specified
  - Controls how often you get reminded about the same alert

Example Timeline:
  T0:  3 alerts arrive â†’ Group starts
  T10s: group_wait expires â†’ First email sent (3 alerts)
  T20s: 1 new alert joins group â†’ group_interval starts
  T30s: group_interval expires â†’ Second email sent (4 alerts)
  T10m: repeat_interval expires â†’ Third email sent (still 4 alerts)

Best Practices:
- Critical alerts: Shorter intervals (group_wait: 5s, repeat_interval: 2m)
- Warning alerts: Longer intervals (group_wait: 30s, repeat_interval: 10m)
- Info alerts: Even longer intervals (group_wait: 1m, repeat_interval: 30m)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
7. PURPOSE OF MULTIPLE RULES IN A GROUP
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Why Have Multiple Rules in a Group?

1. Monitor Different Conditions
   - Each rule monitors different metrics or conditions
   - Example: ServiceDown, HighLatency, ErrorRateHigh, DiskFull

2. Different Severity Levels
   - Different rules can have different severity levels
   - Example: critical for ServiceDown, warning for HighCPU

3. Different Thresholds for Same Metric
   - Multiple rules for same metric with different thresholds
   - Example: CPUWarning (>70%), CPUCritical (>90%)

4. Different Time Windows
   - Different rules can have different 'for' durations
   - Example: ServiceDown (30s), ServiceDegraded (5m)

5. Different Routing
   - Different labels allow different routing in Alertmanager
   - Example: severity=critical â†’ urgent_receiver, severity=warning â†’ main_receiver

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
8. LABEL EVALUATION - WHEN RULES DON'T FIRE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

When Expression is FALSE:
- Alert is in "inactive" state
- Labels and annotations are NOT evaluated
- Template variables ({{ $labels.instance }}) are not populated
- This is by design - Prometheus doesn't waste resources

When Expression is TRUE:
- Alert is in "pending" or "firing" state
- Labels and annotations ARE evaluated
- Template variables are populated with actual values

Key Point: Labels and annotations are only evaluated when the alert is firing

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
9. COMPLETE WORKFLOW EXAMPLE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Scenario: System with 3 alerts configured

Step 1: Prometheus Evaluates Rules
  - Group: SystemAlerts
    * NodeExporterDown: FIRES (up == 0 for 1m)
    * HighCPU: Doesn't fire (CPU is 60%)
    * HighMemory: FIRES (memory is 95%)

Step 2: Prometheus Creates Alerts
  - Alert 1: NodeExporterDown (severity: critical, instance: server1)
  - Alert 2: HighMemory (severity: warning, instance: server1)
  - No alert for HighCPU

Step 3: Alerts Sent to Alertmanager
  - NodeExporterDown â†’ Alertmanager
  - HighMemory â†’ Alertmanager

Step 4: Alertmanager Groups Alerts
  - Group 1: {alertname="NodeExporterDown", severity="critical"}
    â†’ Routes to urgent_receiver (matches severity=critical)
  - Group 2: {alertname="HighMemory", severity="warning"}
    â†’ Routes to main_receiver (default)

Step 5: Email Notifications Sent
  - Email 1: Critical alert for NodeExporterDown
  - Email 2: Warning alert for HighMemory

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
10. KEY TAKEAWAYS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ“ Rules are evaluated independently - each rule operates separately
âœ“ Only firing rules create alerts - non-firing rules don't create alerts
âœ“ Each alert is sent individually to Alertmanager
âœ“ Alertmanager groups alerts by labels for notifications
âœ“ Multiple alerts in same group â†’ ONE email with all alerts listed separately
âœ“ Each alert in email shows full details (labels, annotations, values)
âœ“ Timing configuration controls how often notifications are sent
âœ“ Labels/annotations only evaluated when alert is firing
âœ“ Groups help organize related alerts together
âœ“ Multiple rules allow monitoring different conditions, severities, thresholds

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
INHIBITION RULES & SILENCING IN ALERTMANAGER - COMPREHENSIVE SUMMARY
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
1. INHIBITION RULES - OVERVIEW
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

What is Inhibition?
- Inhibition rules suppress certain alerts when other alerts are firing
- Prevents alert flooding by hiding less important alerts when critical ones fire
- Example: If "ServerDown" is firing, suppress "HighCPU" alerts for that server
- Configured in Alertmanager configuration file (alertmanager.yml)

Key Concept:
  Source Alert (firing) â†’ Inhibits â†’ Target Alerts (suppressed)
  
  When source alert fires, target alerts matching the rule are suppressed
  Target alerts are not sent to receivers while source alert is active

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
2. INHIBITION RULE SYNTAX
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Basic Structure:
  inhibit_rules:
    - source_match:          # Source alert that triggers inhibition
        label_name: value
      target_match:          # Target alerts to be suppressed
        label_name: value
      equal: ['label1', 'label2']  # Labels that must match between source and target

Components:
  source_match: Conditions that identify the source alert (the inhibitor)
  target_match: Conditions that identify target alerts (to be suppressed)
  equal: Labels that must have the same value in both source and target

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
3. INHIBITION RULE EXAMPLES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Example 1: Suppress Warnings When Critical Alerts Fire
  inhibit_rules:
    - source_match:
        severity: critical
      target_match:
        severity: warning
      equal: ['alertname', 'instance']
  
  Meaning:
    - When any critical alert fires
    - Suppress warning alerts with same alertname and instance
    - Prevents getting both critical and warning alerts for same issue

Example 2: Suppress All Alerts When Server is Down
  inhibit_rules:
    - source_match:
        alertname: ServerDown
      target_match:
        severity: warning
      equal: ['instance']
  
  Meaning:
    - When ServerDown alert fires for an instance
    - Suppress all warning alerts for that same instance
    - Makes sense: if server is down, no point alerting about high CPU

Example 3: Suppress Specific Alerts When Parent Alert Fires
  inhibit_rules:
    - source_match:
        alertname: ClusterDown
      target_match:
        alertname: NodeHighCPU
      equal: ['cluster']
  
  Meaning:
    - When ClusterDown fires
    - Suppress NodeHighCPU alerts in the same cluster
    - Cluster-level issue makes node-level alerts irrelevant

Example 4: Multiple Source Conditions
  inhibit_rules:
    - source_match:
        severity: critical
        component: database
      target_match:
        severity: warning
        component: database
      equal: ['instance']
  
  Meaning:
    - When critical database alert fires
    - Suppress warning database alerts for same instance

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
4. HOW INHIBITION WORKS - STEP BY STEP
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Step 1: Alerts Arrive at Alertmanager
  - Alert A: ServerDown (severity: critical, instance: server1)
  - Alert B: HighCPU (severity: warning, instance: server1)
  - Alert C: HighMemory (severity: warning, instance: server1)

Step 2: Inhibition Rules Evaluated
  Rule: source_match {severity: critical} â†’ target_match {severity: warning}
        equal: ['instance']
  
  Check:
    - Source alert (ServerDown) matches source_match? YES (severity: critical)
    - Target alerts (HighCPU, HighMemory) match target_match? YES (severity: warning)
    - Equal labels match? YES (instance: server1 for all)

Step 3: Target Alerts Suppressed
  - Alert A (ServerDown): NOT suppressed (it's the source)
  - Alert B (HighCPU): SUPPRESSED (matches target_match and equal)
  - Alert C (HighMemory): SUPPRESSED (matches target_match and equal)

Step 4: Only Source Alert Sent
  - Only ServerDown alert is sent to receivers
  - HighCPU and HighMemory are suppressed (not sent)

Step 5: When Source Alert Resolves
  - ServerDown alert resolves (server comes back up)
  - Inhibition stops
  - HighCPU and HighMemory alerts can now fire again if conditions still exist

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
5. SILENCING - OVERVIEW
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

What is Silencing?
- Silencing is a manual way to suppress alerts temporarily
- Done through Alertmanager UI or API
- Useful for planned maintenance, known issues, or testing
- More flexible than inhibition rules (can be created/removed on demand)

Key Differences from Inhibition:
  Inhibition Rules:
    - Automatic (configured in alertmanager.yml)
    - Based on alert conditions (source/target matching)
    - Always active when conditions are met
    - Requires configuration change to modify
  
  Silencing:
    - Manual (created through UI/API)
    - Based on matchers (label selectors)
    - Can have time limits (start/end time)
    - Can be created/removed without config changes

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
6. HOW TO CREATE SILENCES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Method 1: Through Alertmanager UI
  1. Go to http://localhost:9093
  2. Click on "Silences" tab
  3. Click "New Silence" button
  4. Fill in:
     - Matchers: Label selectors (e.g., alertname="HighCPU", instance="server1")
     - Starts at: When silence should start
     - Ends at: When silence should end (or duration)
     - Created by: Your name/email
     - Comment: Reason for silence (e.g., "Planned maintenance")
  5. Click "Create"

Method 2: Through API
  POST http://localhost:9093/api/v2/silences
  
  Body:
  {
    "matchers": [
      {"name": "alertname", "value": "HighCPU", "isRegex": false},
      {"name": "instance", "value": "server1", "isRegex": false}
    ],
    "startsAt": "2025-11-08T10:00:00Z",
    "endsAt": "2025-11-08T12:00:00Z",
    "createdBy": "admin@example.com",
    "comment": "Planned maintenance window"
  }

Method 3: Using amtool (Command Line)
  amtool silence add \
    alertname=HighCPU instance=server1 \
    --start=2025-11-08T10:00:00Z \
    --end=2025-11-08T12:00:00Z \
    --comment="Planned maintenance"

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
7. SILENCE MATCHERS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Matchers are label selectors that determine which alerts to silence.

Types of Matchers:
  1. Exact Match:
     alertname="HighCPU"
     instance="server1"
  
  2. Regex Match:
     alertname=~"High.*"
     instance=~"server[0-9]+"
  
  3. Negative Match:
     alertname!="HighCPU"
     severity!="info"

Examples:
  Silence all HighCPU alerts:
    alertname="HighCPU"
  
  Silence all alerts on server1:
    instance="server1"
  
  Silence all critical alerts:
    severity="critical"
  
  Silence HighCPU on specific server:
    alertname="HighCPU"
    instance="server1"
  
  Silence all alerts matching pattern:
    alertname=~"High.*"
    instance=~"server[0-9]+"

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
8. SILENCE DURATION & EXPIRATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Time-Based Silencing:
  - Silences can have start and end times
  - Useful for planned maintenance windows
  - Automatically expires when end time is reached

Example:
  Starts at: 2025-11-08 10:00:00
  Ends at:   2025-11-08 12:00:00
  Duration:  2 hours
  
  - Alerts matching the silence are suppressed from 10:00 to 12:00
  - After 12:00, silence expires and alerts can fire again

Permanent Silences:
  - Can set end time far in the future
  - Or use very long duration
  - Remember to manually expire when no longer needed

Expiring Silences:
  - Silences automatically expire at their end time
  - Can also be manually expired through UI/API
  - Expired silences are kept in history for reference

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
9. INHIBITION VS SILENCING - COMPARISON
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Feature             â”‚ Inhibition Rules      â”‚ Silencing            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Configuration       â”‚ alertmanager.yml      â”‚ UI/API/amtool        â”‚
â”‚ Type                â”‚ Automatic             â”‚ Manual               â”‚
â”‚ Trigger             â”‚ Based on alert state  â”‚ Based on matchers    â”‚
â”‚ Duration            â”‚ While source fires    â”‚ Time-based or manual â”‚
â”‚ Flexibility         â”‚ Fixed rules           â”‚ Very flexible        â”‚
â”‚ Use Case            â”‚ Alert relationships   â”‚ Maintenance/testing  â”‚
â”‚ Modification         â”‚ Config change + reload  â”‚ Instant via UI      â”‚
â”‚ Scope               â”‚ Sourceâ†’Target logic    â”‚ Any matcher pattern  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

When to Use Inhibition:
  âœ“ Automatic suppression based on alert relationships
  âœ“ Reduce alert noise when critical issues occur
  âœ“ Permanent rules for known alert dependencies
  âœ“ Example: Suppress warnings when critical alerts fire

When to Use Silencing:
  âœ“ Planned maintenance windows
  âœ“ Known issues being worked on
  âœ“ Testing alert configurations
  âœ“ Temporary suppression of noisy alerts
  âœ“ One-off situations

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
10. COMPLETE EXAMPLE - INHIBITION RULE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Configuration:
  inhibit_rules:
    - source_match:
        severity: critical
      target_match:
        severity: warning
      equal: ['alertname', 'instance', 'job']

Scenario:
  Alerts Firing:
    1. ServerDown (severity: critical, instance: server1, job: web)
    2. HighCPU (severity: warning, instance: server1, job: web)
    3. HighMemory (severity: warning, instance: server1, job: web)
    4. HighCPU (severity: warning, instance: server2, job: web)

Evaluation:
  Source Match: ServerDown (severity: critical) âœ“
  
  Target Match Check:
    - HighCPU on server1: severity=warning âœ“, equal labels match âœ“ â†’ SUPPRESSED
    - HighMemory on server1: severity=warning âœ“, equal labels match âœ“ â†’ SUPPRESSED
    - HighCPU on server2: severity=warning âœ“, equal labels DON'T match âœ— â†’ NOT SUPPRESSED

Result:
  - ServerDown: Sent (source alert)
  - HighCPU on server1: Suppressed (matches target and equal)
  - HighMemory on server1: Suppressed (matches target and equal)
  - HighCPU on server2: Sent (equal labels don't match - different instance)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
11. COMPLETE EXAMPLE - SILENCING
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Scenario: Planned maintenance on server1 from 10:00 to 12:00

Step 1: Create Silence
  Matchers:
    - instance="server1"
  
  Time:
    - Starts: 2025-11-08 10:00:00
    - Ends:   2025-11-08 12:00:00
  
  Comment: "Planned maintenance - server1"

Step 2: During Maintenance
  Alerts that would fire:
    - ServerDown (instance: server1) â†’ SUPPRESSED by silence
    - HighCPU (instance: server1) â†’ SUPPRESSED by silence
    - HighMemory (instance: server1) â†’ SUPPRESSED by silence
    - HighCPU (instance: server2) â†’ NOT suppressed (different instance)

Step 3: After Maintenance
  - Silence expires at 12:00
  - Alerts for server1 can fire again normally

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
12. BEST PRACTICES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Inhibition Rules:
  âœ“ Keep rules simple and clear
  âœ“ Document why each rule exists
  âœ“ Test rules carefully before deploying
  âœ“ Use 'equal' labels to ensure proper matching
  âœ“ Don't over-inhibit - you might miss important alerts

Silencing:
  âœ“ Always add comments explaining why silence was created
  âœ“ Set appropriate end times (don't leave permanent silences)
  âœ“ Review and expire old silences regularly
  âœ“ Use specific matchers (don't silence too broadly)
  âœ“ Document maintenance windows in silence comments

General:
  âœ“ Use inhibition for automatic, permanent relationships
  âœ“ Use silencing for temporary, manual situations
  âœ“ Monitor silenced alerts to ensure they're appropriate
  âœ“ Review silence history periodically
  âœ“ Combine both: inhibition for logic, silencing for exceptions

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
13. COMMON USE CASES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Inhibition Use Cases:
  1. Suppress warnings when critical alerts fire
  2. Suppress node-level alerts when cluster-level alert fires
  3. Suppress application alerts when infrastructure alert fires
  4. Suppress dependent alerts when root cause alert fires

Silencing Use Cases:
  1. Planned maintenance windows
  2. Known issues being actively worked on
  3. Testing alert configurations
  4. Suppressing noisy alerts temporarily
  5. Scheduled downtime periods
  6. Development/testing environments

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
14. KEY TAKEAWAYS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Inhibition Rules:
  âœ“ Automatic suppression based on alert relationships
  âœ“ Configured in alertmanager.yml
  âœ“ Source alert suppresses target alerts
  âœ“ Uses source_match, target_match, and equal labels
  âœ“ Active while source alert is firing

Silencing:
  âœ“ Manual suppression via UI/API/amtool
  âœ“ Based on label matchers
  âœ“ Can be time-limited
  âœ“ More flexible than inhibition
  âœ“ Useful for temporary situations

Both:
  âœ“ Help reduce alert noise
  âœ“ Prevent alert flooding
  âœ“ Improve signal-to-noise ratio
  âœ“ Should be used thoughtfully
  âœ“ Need proper documentation

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
RECORDING RULES IN PROMETHEUS - COMPREHENSIVE SUMMARY
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
1. WHAT ARE RECORDING RULES?
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Definition:
- Recording rules pre-compute frequently used or expensive queries
- They store the result as a new time series with a new metric name
- Results are stored in Prometheus's time series database
- Can be queried like any other metric

Purpose:
- Improve query performance (pre-compute expensive calculations)
- Simplify complex queries (create reusable metrics)
- Reduce query load on Prometheus
- Create aggregated metrics for dashboards
- Standardize metric names across environments

Key Difference from Alert Rules:
  Alert Rules:
    - Evaluate conditions and create alerts
    - Don't store new metrics
    - Used for alerting only
  
  Recording Rules:
    - Evaluate expressions and store results as new metrics
    - Create new time series data
    - Used for querying and dashboards

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
2. RECORDING RULE SYNTAX
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Basic Structure:
  groups:
    - name: group_name
      interval: 30s  # Optional: evaluation interval
      rules:
        - record: new_metric_name
          expr: promql_expression

Components:
  record: The name of the new metric to create
  expr: The PromQL expression to evaluate
  labels: Optional labels to add to the new metric

Example:
  groups:
    - name: cpu_recording_rules
      interval: 30s
      rules:
        - record: instance:node_cpu_usage:rate5m
          expr: 100 - (avg(irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
3. WHY USE RECORDING RULES?
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. Performance Optimization
   - Pre-compute expensive queries (aggregations, rate calculations)
   - Reduce query time for dashboards
   - Lower CPU usage on Prometheus server
   - Faster response times for frequently accessed metrics

2. Query Simplification
   - Complex expressions become simple metric queries
   - Example: Instead of:
       rate(http_requests_total[5m]) / rate(http_requests_total[5m]) * 100
     Use pre-computed: http_request_error_rate

3. Reusability
   - Define once, use everywhere
   - Consistent calculations across dashboards
   - Easier to maintain

4. Aggregation
   - Create cluster-level, service-level, or environment-level metrics
   - Aggregate across multiple instances
   - Create summary metrics

5. Standardization
   - Consistent metric naming conventions
   - Standardize metric names across different exporters
   - Create unified metrics from different sources

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
4. RECORDING RULE EXAMPLES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Example 1: CPU Usage Percentage
  groups:
    - name: cpu_recording_rules
      rules:
        - record: instance:node_cpu_usage:rate5m
          expr: |
            100 - (
              avg(irate(node_cpu_seconds_total{mode="idle"}[5m])) 
              * 100
            )
  
  Usage: Query `instance:node_cpu_usage:rate5m` instead of complex expression

Example 2: Memory Usage Percentage
  groups:
    - name: memory_recording_rules
      rules:
        - record: instance:node_memory_usage:ratio
          expr: |
            (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) 
            / node_memory_MemTotal_bytes
  
  Usage: Query `instance:node_memory_usage:ratio` for memory usage

Example 3: HTTP Request Rate
  groups:
    - name: http_recording_rules
      rules:
        - record: http:requests:rate5m
          expr: rate(http_requests_total[5m])
  
  Usage: Query `http:requests:rate5m` instead of `rate(http_requests_total[5m])`

Example 4: Error Rate Percentage
  groups:
    - name: http_recording_rules
      rules:
        - record: http:request_error_rate:ratio
          expr: |
            rate(http_requests_total{status=~"5.."}[5m]) 
            / rate(http_requests_total[5m])
  
  Usage: Query `http:request_error_rate:ratio` for error percentage

Example 5: Aggregated Metrics
  groups:
    - name: cluster_recording_rules
      rules:
        - record: cluster:cpu_usage:avg
          expr: avg(instance:node_cpu_usage:rate5m)
          labels:
            cluster: production
        
        - record: cluster:memory_usage:avg
          expr: avg(instance:node_memory_usage:ratio)
          labels:
            cluster: production

Example 6: Multi-step Calculation
  groups:
    - name: service_recording_rules
      rules:
        # Step 1: Calculate request rate
        - record: service:http_requests:rate5m
          expr: rate(http_requests_total[5m])
        
        # Step 2: Calculate error rate using step 1
        - record: service:http_errors:rate5m
          expr: rate(http_requests_total{status=~"5.."}[5m])
        
        # Step 3: Calculate error percentage using steps 1 and 2
        - record: service:http_error_rate:ratio
          expr: |
            service:http_errors:rate5m 
            / service:http_requests:rate5m

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
5. NAMING CONVENTIONS FOR RECORDING RULES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Best Practice Naming Pattern:
  level:metric:operation

Components:
  level: The aggregation level (instance, service, cluster, etc.)
  metric: The metric name being recorded
  operation: The operation performed (rate, sum, avg, ratio, etc.)

Examples:
  instance:node_cpu_usage:rate5m
    - level: instance (per-instance metric)
    - metric: node_cpu_usage
    - operation: rate5m (5-minute rate)
  
  cluster:http_requests:sum
    - level: cluster (cluster-wide)
    - metric: http_requests
    - operation: sum (summed across instances)
  
  service:memory_usage:avg
    - level: service (service-level)
    - metric: memory_usage
    - operation: avg (averaged)

Common Operations:
  :rate5m    - 5-minute rate
  :rate1m    - 1-minute rate
  :sum       - Summed value
  :avg       - Average value
  :max       - Maximum value
  :min       - Minimum value
  :ratio     - Ratio/percentage
  :increase  - Increase over time

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
6. HOW TO SAVE RECORDING RULES - FILE ORGANIZATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Best Practice: Separate Files by Purpose

Option 1: Separate Files (RECOMMENDED)
  Directory Structure:
    /usr/local/etc/rule/
      â”œâ”€â”€ alerts.yml          # Alert rules only
      â”œâ”€â”€ recording_cpu.yml    # CPU-related recording rules
      â”œâ”€â”€ recording_memory.yml # Memory-related recording rules
      â”œâ”€â”€ recording_http.yml  # HTTP-related recording rules
      â””â”€â”€ recording_cluster.yml # Cluster-level recording rules

  prometheus.yml:
    rule_files:
      - "/usr/local/etc/rule/alerts.yml"
      - "/usr/local/etc/rule/recording_cpu.yml"
      - "/usr/local/etc/rule/recording_memory.yml"
      - "/usr/local/etc/rule/recording_http.yml"
      - "/usr/local/etc/rule/recording_cluster.yml"

Option 2: Single File with Groups
  File: /usr/local/etc/rule/recording_rules.yml
  
  groups:
    - name: cpu_recording_rules
      rules: [...]
    - name: memory_recording_rules
      rules: [...]
    - name: http_recording_rules
      rules: [...]

  prometheus.yml:
    rule_files:
      - "/usr/local/etc/rule/alerts.yml"
      - "/usr/local/etc/rule/recording_rules.yml"

Option 3: By Service/Component
  Directory Structure:
    /usr/local/etc/rule/
      â”œâ”€â”€ alerts.yml
      â”œâ”€â”€ node_exporter_recording.yml
      â”œâ”€â”€ application_recording.yml
      â””â”€â”€ infrastructure_recording.yml

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
7. CONFIGURING RECORDING RULES IN PROMETHEUS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Step 1: Create Recording Rules File
  Create file: /usr/local/etc/rule/recording_rules.yml
  
  groups:
    - name: cpu_recording_rules
      interval: 30s
      rules:
        - record: instance:node_cpu_usage:rate5m
          expr: 100 - (avg(irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)

Step 2: Add to prometheus.yml
  rule_files:
    - "/usr/local/etc/rule/alerts.yml"
    - "/usr/local/etc/rule/recording_rules.yml"

Step 3: Reload Prometheus
  curl -X POST http://localhost:9090/-/reload
  
  Or restart Prometheus service

Step 4: Verify Rules Are Loaded
  - Go to http://localhost:9090/rules
  - Check that recording rules appear
  - Verify they're being evaluated

Step 5: Query the New Metric
  - In Prometheus UI, query: instance:node_cpu_usage:rate5m
  - Should return time series data

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
8. BEST PRACTICES FOR SAVING RECORDING RULES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. File Organization
   âœ“ Separate recording rules from alert rules
   âœ“ Group related rules together
   âœ“ Use descriptive file names
   âœ“ Keep files focused and manageable size
   âœ“ Document what each file contains

2. Naming Conventions
   âœ“ Use consistent naming pattern (level:metric:operation)
   âœ“ Make names descriptive and self-documenting
   âœ“ Avoid generic names like "metric1", "metric2"
   âœ“ Include operation type in name (rate, sum, avg)
   âœ“ Use underscores, not hyphens or spaces

3. Group Organization
   âœ“ Group by metric type (CPU, memory, network)
   âœ“ Group by service/component
   âœ“ Group by aggregation level (instance, cluster)
   âœ“ Use descriptive group names
   âœ“ Keep groups focused on single purpose

4. Evaluation Intervals
   âœ“ Set appropriate intervals based on use case
   âœ“ Shorter intervals for frequently queried metrics
   âœ“ Longer intervals for less critical metrics
   âœ“ Consider query frequency when setting intervals
   âœ“ Default: Uses global evaluation_interval if not specified

5. Documentation
   âœ“ Add comments explaining complex expressions
   âœ“ Document why recording rule exists
   âœ“ Note dependencies between rules
   âœ“ Include examples of how to use the metric
   âœ“ Document any assumptions or limitations

6. Version Control
   âœ“ Store rules in version control (git)
   âœ“ Use same workflow as alert rules
   âœ“ Review changes before deploying
   âœ“ Test rules in development first
   âœ“ Keep history of changes

7. Testing
   âœ“ Test expressions in Prometheus UI first
   âœ“ Verify results match expectations
   âœ“ Check for errors in Prometheus logs
   âœ“ Monitor rule evaluation performance
   âœ“ Validate metric names are correct

8. Maintenance
   âœ“ Review unused recording rules periodically
   âœ“ Remove obsolete rules
   âœ“ Update rules when source metrics change
   âœ“ Monitor rule evaluation time
   âœ“ Optimize expensive rules

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
9. COMPLETE EXAMPLE - RECORDING RULES FILE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

File: /usr/local/etc/rule/recording_rules.yml

groups:
  # CPU-related recording rules
  - name: cpu_recording_rules
    interval: 30s
    rules:
      # CPU usage percentage (5-minute rate)
      - record: instance:node_cpu_usage:rate5m
        expr: |
          100 - (
            avg(irate(node_cpu_seconds_total{mode="idle"}[5m])) 
            * 100
          )
      
      # CPU usage by mode
      - record: instance:node_cpu_seconds:rate5m
        expr: rate(node_cpu_seconds_total[5m])
  
  # Memory-related recording rules
  - name: memory_recording_rules
    interval: 30s
    rules:
      # Memory usage ratio
      - record: instance:node_memory_usage:ratio
        expr: |
          (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) 
          / node_memory_MemTotal_bytes
      
      # Memory usage percentage
      - record: instance:node_memory_usage:percent
        expr: |
          (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) 
          / node_memory_MemTotal_bytes 
          * 100
  
  # Disk-related recording rules
  - name: disk_recording_rules
    interval: 1m
    rules:
      # Disk usage ratio
      - record: instance:node_filesystem_usage:ratio
        expr: |
          (node_filesystem_size_bytes - node_filesystem_avail_bytes) 
          / node_filesystem_size_bytes
      
      # Disk usage percentage
      - record: instance:node_filesystem_usage:percent
        expr: |
          (node_filesystem_size_bytes - node_filesystem_avail_bytes) 
          / node_filesystem_size_bytes 
          * 100

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
10. INTEGRATION WITH YOUR CURRENT SETUP
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Current Setup:
  - Config files in: /usr/local/etc/
  - Alert rules in: /usr/local/etc/rule/alerts.yml
  - Repo tracking: config/rule/alerts.yml
  - Sync script: sync-config.sh

Recommended Addition:
  1. Create recording rules file:
     config/rule/recording_rules.yml
  
  2. Update prometheus.yml:
     rule_files:
       - "/usr/local/etc/rule/alerts.yml"
       - "/usr/local/etc/rule/recording_rules.yml"
  
  3. Update sync-config.sh to include recording rules:
     sudo cp config/rule/recording_rules.yml /usr/local/etc/rule/recording_rules.yml
  
  4. Sync and reload:
     ./sync-config.sh
     curl -X POST http://localhost:9090/-/reload

Directory Structure:
  config/
    â”œâ”€â”€ prometheus.yml
    â””â”€â”€ rule/
        â”œâ”€â”€ alerts.yml
        â””â”€â”€ recording_rules.yml

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
11. COMMON PATTERNS AND USE CASES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Pattern 1: Rate Calculations
  - Pre-compute rate() for frequently queried counters
  - Reduces query time for dashboards
  - Example: HTTP request rates, error rates

Pattern 2: Aggregations
  - Create cluster/service-level metrics
  - Aggregate across multiple instances
  - Example: Average CPU across cluster

Pattern 3: Percentages and Ratios
  - Convert raw values to percentages
  - Calculate ratios between metrics
  - Example: CPU usage %, error rate %

Pattern 4: Multi-step Calculations
  - Break complex calculations into steps
  - Each step creates a reusable metric
  - Example: Error rate = errors / total requests

Pattern 5: Standardization
  - Normalize metric names from different exporters
  - Create unified naming conventions
  - Example: Standardize CPU metric names

Pattern 6: Historical Aggregations
  - Pre-compute aggregations over time windows
  - Useful for long-term trends
  - Example: Daily/weekly averages

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
12. MONITORING RECORDING RULES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Check Rule Status:
  - Prometheus UI: http://localhost:9090/rules
  - Shows all recording rules and their status
  - Indicates if rules are being evaluated

Check Rule Performance:
  - Prometheus UI: http://localhost:9090/rules
  - Shows evaluation time for each rule
  - Monitor for slow rules

Check Metrics Exist:
  - Query the recorded metric in Prometheus UI
  - Verify data is being stored
  - Check metric labels are correct

Common Issues:
  - Rules not loading: Check file path in prometheus.yml
  - No data: Check source metrics exist
  - Errors: Check Prometheus logs
  - Slow evaluation: Optimize expressions or increase interval

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
13. KEY TAKEAWAYS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ“ Recording rules pre-compute and store query results as new metrics
âœ“ Use them to improve performance and simplify queries
âœ“ Follow naming convention: level:metric:operation
âœ“ Separate recording rules from alert rules in different files
âœ“ Organize rules by purpose (CPU, memory, HTTP, etc.)
âœ“ Set appropriate evaluation intervals
âœ“ Document complex expressions
âœ“ Test rules before deploying
âœ“ Monitor rule performance
âœ“ Keep rules in version control
âœ“ Use consistent file organization
âœ“ Group related rules together

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
PUSHGATEWAY - SUMMARY AND PROMETHEUS CONFIG CHANGES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

What is Pushgateway?
- A service that accepts metrics pushed by shortâ€‘lived/batch jobs and exposes them to Prometheus via /metrics (default port 9091).
- Not a general-purpose ingestion layer; avoid using it for longâ€‘running services that can be scraped directly.

When to use
- Cron jobs, CI/CD steps, and ephemeral batch jobs that exit before Prometheus can scrape them.

Prometheus scrape config (preserve pushed labels):

  scrape_configs:
    - job_name: "pushgateway"
      honor_labels: true        # keep job/instance from pushed metrics
      static_configs:
        - targets: ["localhost:9091"]

Why honor_labels: true?
- Pushgateway encodes the grouping key (e.g., job, instance) as labels.
- Without honor_labels, the scraperâ€™s labels (job="pushgateway", instance="host:9091") would override the pushed labels.

Pushing metrics (HTTP API)
- Create/replace:   PUT  /metrics/job/<job_name>[/instance/<instance>]
- Add/merge:        POST /metrics/job/<job_name>[/instance/<instance>]
- Delete all for job:       DELETE /metrics/job/<job_name>
- Delete one instance:      DELETE /metrics/job/<job_name>/instance/<instance>

Examples (text exposition format):

  # push for a job and instance
  curl -X PUT \
    --data-binary "# HELP my_job_last_success Unix time of last success
# TYPE my_job_last_success gauge
my_job_last_success $(date +%s)" \
    http://localhost:9091/metrics/job/my_batch/instance/host1

  # delete metrics for that instance
  curl -X DELETE http://localhost:9091/metrics/job/my_batch/instance/host1

Best practices
- Use distinct job and instance values in the push URL; avoid embedding hostnames in metric names.
- Keep payloads small and metric/label names stable and consistent.
- Delete metrics on successful completion to avoid stale data.
- Do not expose Pushgateway publicly; protect with network controls or an auth proxy.
- Consider recording rules on top of pushed metrics for dashboards.

Running the binary
- From project root: ./pushgateway/pushgateway  (listens on port 9091)
- Check version/type: ./pushgateway/pushgateway --version
- If not executable: chmod +x pushgateway/pushgateway
==============================================

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
COLLECTORREGISTRY IN PROMETHEUS CLIENT - SUMMARY
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
1. WHAT IS COLLECTORREGISTRY?
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Definition:
- CollectorRegistry is a component from Prometheus client libraries that manages
  metric collectors and formats them for Prometheus consumption
- Acts as a container/organizer for metrics in your application
- Client-side component (not part of Prometheus server)

Purpose:
- Tracks and manages all metric collectors in your application
- Formats metrics in Prometheus exposition format
- Provides metrics when /metrics endpoint is scraped
- Organizes metrics for exposure to Prometheus

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
2. WHEN IS REGISTRY CREATED?
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

In Pushgateway:
- Registry is created ONCE when Pushgateway starts up
- Single registry instance persists for entire process lifetime
- All push requests use the same registry
- Metrics accumulate in registry until deleted or restart
- On restart: New empty registry created (previous metrics lost unless persisted)

In Client Applications:
- Default Registry: Created automatically by Prometheus client library
  - Global singleton instance
  - All metrics automatically registered to it
  - Used when exposing /metrics endpoint
  
- Custom Registry: Created explicitly by developer
  - Created when you call: CollectorRegistry()
  - Isolated from default registry
  - Useful for pushing to Pushgateway, testing, or multiple metric sets

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
3. WHAT HAPPENS WHEN YOU CALL COLLECTORREGISTRY METHODS?
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Creating a Registry:
  registry = CollectorRegistry()
  â†’ Creates empty registry instance
  â†’ Initializes internal data structures
  â†’ Ready to accept metric collectors
  â†’ No metrics registered yet

Registering a Metric:
  counter = Counter('http_requests_total', registry=registry)
  â†’ Metric added to registry's internal collection
  â†’ Registry tracks metric's name, type, labels, current value
  â†’ Registry maintains reference to collector
  â†’ Metric will appear when /metrics is scraped

Registering Multiple Metrics:
  counter = Counter('requests', registry=registry)
  gauge = Gauge('connections', registry=registry)
  â†’ Each metric stored separately in registry
  â†’ Registry maintains list/map of all registered collectors
  â†’ All collectors tracked together
  â†’ All metrics formatted together when exposed

Collecting Metrics (formatting):
  output = generate_latest(registry)
  â†’ Registry iterates through all registered collectors
  â†’ Calls collect() on each collector to get current values
  â†’ Formats each metric in Prometheus exposition format
  â†’ Returns string with all metrics formatted for Prometheus

Unregistering a Collector:
  registry.unregister(counter)
  â†’ Removes collector from registry's internal collection
  â†’ Metric no longer tracked
  â†’ Won't appear in future /metrics output
  â†’ Memory freed (if no other references)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
4. KEY METHODS AND THEIR EFFECTS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

register(collector):
  - Adds collector to registry
  - Registry starts tracking this collector
  - Collector will appear in /metrics output

unregister(collector):
  - Removes collector from registry
  - Collector no longer tracked
  - Won't appear in future /metrics output

collect() (internal):
  - Iterates through all registered collectors
  - Calls each collector's collect() method
  - Gathers current metric values
  - Returns formatted metric data

get_sample_value(metric_name):
  - Looks up specific metric in registry
  - Returns current value of that metric
  - Useful for programmatic access

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
5. DEFAULT REGISTRY VS CUSTOM REGISTRY
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Default Registry (Automatic):
  from prometheus_client import Counter
  
  counter = Counter('http_requests_total')
  # Uses default registry automatically
  
  â†’ Prometheus client maintains global default registry
  â†’ Metrics automatically registered to default registry
  â†’ When you expose /metrics, it uses default registry
  â†’ All metrics share same default registry

Custom Registry (Explicit):
  from prometheus_client import CollectorRegistry, Counter
  
  registry = CollectorRegistry()
  counter = Counter('http_requests_total', registry=registry)
  
  â†’ Creates separate, isolated registry
  â†’ Metrics only in this custom registry
  â†’ Useful for:
    * Pushing to Pushgateway (isolated metrics)
    * Multiple metric sets
    * Testing (separate test metrics)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
6. COMPLETE FLOW EXAMPLE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Step 1: Create registry
  registry = CollectorRegistry()
  â†’ Empty registry created

Step 2: Create and register metrics
  counter = Counter('requests_total', registry=registry)
  gauge = Gauge('active_connections', registry=registry)
  â†’ Metrics added to registry's internal collection

Step 3: Update metrics
  counter.inc()  # Increment counter
  gauge.set(10)  # Set gauge value
  â†’ Metric values updated, registry still tracks them

Step 4: Collect and format (when /metrics is scraped)
  output = generate_latest(registry)
  â†’ Registry:
    1. Iterates through all registered collectors
    2. Calls collect() on each to get current values
    3. Formats in Prometheus exposition format
    4. Returns formatted string

Output:
  # HELP requests_total ...
  # TYPE requests_total counter
  requests_total 1.0
  # HELP active_connections ...
  # TYPE active_connections gauge
  active_connections 10.0

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
7. REGISTRY STATE MANAGEMENT
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Registry Maintains:
  âœ“ List of all registered collectors
  âœ“ Metric metadata (names, types, help text)
  âœ“ Current metric values (via collectors)
  âœ“ Label combinations for each metric

Registry Does NOT:
  âœ— Store historical values (Prometheus does that)
  âœ— Persist data to disk (in-memory only)
  âœ— Send metrics to Prometheus (Prometheus pulls from /metrics)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
8. KEY TAKEAWAYS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ“ CollectorRegistry is a client-side metric manager
âœ“ Created once at startup (Pushgateway) or when needed (client apps)
âœ“ Tracks all registered metric collectors
âœ“ Formats metrics for Prometheus exposition format
âœ“ Provides metrics when /metrics endpoint is scraped
âœ“ Default registry is automatic, custom registry is explicit
âœ“ Registry maintains current state, not historical data
âœ“ Metrics persist in registry until unregistered or app restarts
âœ“ In Pushgateway: Single registry for entire process lifetime
âœ“ In Client Apps: Can have multiple registries for different purposes

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
PROMETHEUS AUTHENTICATION METHODS - SUMMARY
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
1. OVERVIEW
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Important Note:
- Prometheus does NOT have built-in authentication for UI/API
- By default, Prometheus UI and API are unauthenticated
- Authentication must be added via external methods or web.config.file
- Scrape target authentication IS built-in
- Alertmanager authentication IS built-in
- Remote write authentication IS built-in

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
2. UI/API AUTHENTICATION METHODS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Method 1: Reverse Proxy with Authentication
  - Use reverse proxy (nginx, Apache, Traefik) in front of Prometheus
  - Proxy handles authentication, Prometheus runs behind it
  - Supports: Basic Auth, OAuth2, LDAP, SAML, JWT, API keys
  
  Example (Nginx Basic Auth):
    server {
      listen 9090;
      location / {
        auth_basic "Prometheus";
        auth_basic_user_file /etc/nginx/.htpasswd;
        proxy_pass http://localhost:9090;
      }
    }

Method 2: Web Configuration File (Prometheus 2.x+)
  - Configure TLS and basic authentication via web.config.file
  - Supports TLS, basic auth, and headers
  
  web-config.yml:
    tls_server_config:
      cert_file: /path/to/cert.pem
      key_file: /path/to/key.pem
    
    basic_auth_users:
      admin: $2y$10$hashed_password
      user: $2y$10$hashed_password
  
  Start Prometheus:
    prometheus --web.config.file=web-config.yml
  
  Generate password hash:
    htpasswd -nBC 10 admin

Method 3: TLS/SSL (HTTPS)
  - Encrypts traffic between client and Prometheus
  - Does NOT authenticate users, but secures communication
  - Requires certificates
  
  web-config.yml:
    tls_server_config:
      cert_file: /path/to/cert.pem
      key_file: /path/to/key.pem

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
3. SCRAPE TARGET AUTHENTICATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Basic Authentication:
  scrape_configs:
    - job_name: 'secure-service'
      basic_auth:
        username: 'scraper'
        password: 'secret'
      static_configs:
        - targets: ['service:8080']

Bearer Token:
  scrape_configs:
    - job_name: 'api-service'
      bearer_token: 'your-bearer-token-here'
      static_configs:
        - targets: ['api:8080']

Bearer Token File:
  scrape_configs:
    - job_name: 'api-service'
      bearer_token_file: '/path/to/token'
      static_configs:
        - targets: ['api:8080']

TLS Configuration:
  scrape_configs:
    - job_name: 'secure-service'
      scheme: https
      tls_config:
        ca_file: /path/to/ca.crt
        cert_file: /path/to/client.crt
        key_file: /path/to/client.key
        insecure_skip_verify: false
      static_configs:
        - targets: ['service:8443']

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
4. ALERTMANAGER AUTHENTICATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Basic Authentication:
  alerting:
    alertmanagers:
      - basic_auth:
          username: 'prometheus'
          password: 'secret'
        static_configs:
          - targets:
            - 'alertmanager:9093'

Bearer Token:
  alerting:
    alertmanagers:
      - bearer_token: 'alertmanager-token'
        static_configs:
          - targets:
            - 'alertmanager:9093'

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
5. REMOTE WRITE AUTHENTICATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Basic Authentication:
  remote_write:
    - url: 'https://remote-storage/api/v1/write'
      basic_auth:
        username: 'prometheus'
        password: 'secret'

Bearer Token:
  remote_write:
    - url: 'https://remote-storage/api/v1/write'
      bearer_token: 'remote-token'

OAuth2:
  remote_write:
    - url: 'https://remote-storage/api/v1/write'
      oauth2:
        client_id: 'prometheus'
        client_secret: 'secret'
        token_url: 'https://auth-server/oauth/token'

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
6. NETWORK-LEVEL SECURITY
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Methods:
  - Firewall rules (restrict access to specific IPs)
  - VPN access (require VPN connection)
  - Private networks (deploy in private network)
  - IP whitelisting (via reverse proxy)

Use Cases:
  - Additional layer of security
  - Network isolation
  - Defense in depth

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
7. KUBERNETES AUTHENTICATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Methods:
  - Service accounts and RBAC (Kubernetes native auth)
  - Network policies (restrict pod-to-pod communication)
  - Ingress with authentication (Ingress controller with auth)
  - mTLS between pods (service mesh)

Service Mesh (Istio, Linkerd):
  - Automatic mTLS between services
  - Works well in Kubernetes
  - Provides encryption and authentication

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
8. AUTHENTICATION METHODS SUMMARY TABLE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Method               â”‚ Use Case         â”‚ Where Applied     â”‚ Built-in    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Reverse Proxy        â”‚ UI/API access    â”‚ Front of Prometheusâ”‚ No (external)â”‚
â”‚ Web Config File      â”‚ UI/API access    â”‚ Prometheus config â”‚ Yes (2.x+)  â”‚
â”‚ TLS/SSL              â”‚ Encryption       â”‚ Prometheus server â”‚ Yes         â”‚
â”‚ Basic Auth (scrape)  â”‚ Target scraping  â”‚ scrape_configs    â”‚ Yes         â”‚
â”‚ Bearer Token (scrape)â”‚ Target scraping  â”‚ scrape_configs    â”‚ Yes         â”‚
â”‚ TLS (scrape)         â”‚ Secure targets   â”‚ scrape_configs    â”‚ Yes         â”‚
â”‚ Alertmanager Auth    â”‚ Sending alerts   â”‚ alerting config   â”‚ Yes         â”‚
â”‚ Remote Write Auth    â”‚ Remote storage   â”‚ remote_write      â”‚ Yes         â”‚
â”‚ Network Security     â”‚ Network level    â”‚ Infrastructure    â”‚ No (external)â”‚
â”‚ Service Mesh         â”‚ mTLS in K8s      â”‚ Infrastructure    â”‚ No (external)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
9. BEST PRACTICES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

UI/API Access:
  âœ“ Use reverse proxy for production deployments
  âœ“ Enable TLS for encrypted communication
  âœ“ Use web.config.file for simple setups
  âœ“ Implement strong password policies

Scrape Targets:
  âœ“ Use basic auth or bearer tokens for authenticated targets
  âœ“ Use TLS for encrypted communication
  âœ“ Store credentials securely (secret management)
  âœ“ Use separate credentials per service/job

Alertmanager:
  âœ“ Authenticate connections to Alertmanager
  âœ“ Use bearer tokens for better security
  âœ“ Store tokens securely

Remote Write:
  âœ“ Authenticate all remote write endpoints
  âœ“ Use OAuth2 for cloud services
  âœ“ Rotate credentials regularly

General:
  âœ“ Use network-level security as additional layer
  âœ“ Restrict network access (firewalls, private networks)
  âœ“ Rotate credentials regularly
  âœ“ Use separate credentials per service/job
  âœ“ Store secrets securely (secret management systems)
  âœ“ Monitor authentication failures
  âœ“ Use service accounts in Kubernetes
  âœ“ Implement defense in depth (multiple layers)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
10. KEY TAKEAWAYS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ“ Prometheus has NO built-in UI/API authentication
âœ“ Authentication must be added via external methods or web.config.file
âœ“ Scrape target authentication IS built-in (basic auth, bearer token, TLS)
âœ“ Alertmanager authentication IS built-in
âœ“ Remote write authentication IS built-in
âœ“ Use reverse proxy for production UI/API access
âœ“ Use web.config.file for simple authentication setups
âœ“ Always use TLS for encrypted communication
âœ“ Store credentials securely
âœ“ Use network-level security as additional layer
âœ“ Rotate credentials regularly
âœ“ Use separate credentials per service/job

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
GRAFANA INSTALLATION INSTRUCTIONS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. INSTALLATION ON macOS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Method 1: Using Homebrew (Recommended)
  brew install grafana

  Start Grafana:
  brew services start grafana

  Or run manually:
  grafana-server --config=/usr/local/etc/grafana/grafana.ini

  Default configuration location: /usr/local/etc/grafana/grafana.ini
  Default data directory: /usr/local/var/lib/grafana
  Default log directory: /usr/local/var/log/grafana
  Default port: 3000

  Access Grafana: http://localhost:3000
  Default credentials:
    Username: admin
    Password: admin (you'll be prompted to change on first login)


Method 2: Using Standalone Binary
  # Download Grafana
  wget https://dl.grafana.com/oss/release/grafana-10.x.x.darwin-amd64.tar.gz
  tar -zxvf grafana-10.x.x.darwin-amd64.tar.gz
  cd grafana-10.x.x

  # Run Grafana
  ./bin/grafana-server

  # Or specify config file
  ./bin/grafana-server --config=/path/to/grafana.ini


2. INSTALLATION ON AWS EC2 (Linux/Ubuntu)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Method 1: Using APT Repository (Recommended for Ubuntu/Debian)

  # Update system packages
  sudo apt-get update
  sudo apt-get install -y software-properties-common

  # Add Grafana's official APT repository
  sudo apt-get install -y apt-transport-https
  sudo apt-get install -y software-properties-common wget
  wget -q -O - https://packages.grafana.com/gpg.key | sudo apt-key add -

  # Add Grafana repository
  echo "deb https://packages.grafana.com/oss/deb stable main" | sudo tee -a /etc/apt/sources.list.d/grafana.list

  # Update and install Grafana
  sudo apt-get update
  sudo apt-get install -y grafana

  # Start and enable Grafana service
  sudo systemctl daemon-reload
  sudo systemctl start grafana-server
  sudo systemctl enable grafana-server

  # Check status
  sudo systemctl status grafana-server

  Configuration location: /etc/grafana/grafana.ini
  Data directory: /var/lib/grafana
  Log directory: /var/log/grafana
  Default port: 3000

  Access Grafana: http://<EC2-IP>:3000
  (Make sure security group allows inbound traffic on port 3000)


Method 2: Using Standalone Binary (Linux)

  # Download Grafana
  wget https://dl.grafana.com/oss/release/grafana-10.x.x.linux-amd64.tar.gz
  tar -zxvf grafana-10.x.x.linux-amd64.tar.gz
  cd grafana-10.x.x

  # Create systemd service (optional, for running as service)
  sudo nano /etc/systemd/system/grafana.service

  [Unit]
  Description=Grafana Server
  After=network.target

  [Service]
  Type=simple
  User=grafana
  ExecStart=/path/to/grafana/bin/grafana-server --config=/etc/grafana/grafana.ini
  Restart=on-failure

  [Install]
  WantedBy=multi-user.target

  # Enable and start service
  sudo systemctl daemon-reload
  sudo systemctl enable grafana
  sudo systemctl start grafana


Method 3: Using Docker (Works on any Linux EC2)

  # Pull Grafana image
  docker pull grafana/grafana

  # Run Grafana container
  docker run -d \
    -p 3000:3000 \
    --name=grafana \
    -v grafana-storage:/var/lib/grafana \
    -e "GF_SECURITY_ADMIN_PASSWORD=admin" \
    grafana/grafana

  # Or with custom config file
  docker run -d \
    -p 3000:3000 \
    --name=grafana \
    -v /path/to/grafana.ini:/etc/grafana/grafana.ini \
    -v grafana-storage:/var/lib/grafana \
    grafana/grafana

  # Using docker-compose
  # Create docker-compose.yml:
  version: '3'
  services:
    grafana:
      image: grafana/grafana
      ports:
        - "3000:3000"
      volumes:
        - grafana-storage:/var/lib/grafana
        - ./config/grafana.ini:/etc/grafana/grafana.ini
      environment:
        - GF_SECURITY_ADMIN_PASSWORD=admin

  volumes:
    grafana-storage:


3. INSTALLATION ON AWS (General)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

AWS ECS (Elastic Container Service):
  - Use Grafana Docker image in ECS task definition
  - Configure ECS service with appropriate ports and volumes
  - Use ECS service discovery or ALB for access

AWS EKS (Elastic Kubernetes Service):
  - Deploy Grafana using Helm chart:
    helm repo add grafana https://grafana.github.io/helm-charts
    helm repo update
    helm install grafana grafana/grafana

  - Or use Kubernetes manifests:
    kubectl apply -f https://raw.githubusercontent.com/grafana/grafana/main/k8s/grafana-deployment.yaml

AWS Lambda (Grafana Cloud):
  - Use Grafana Cloud for serverless monitoring
  - Not for self-hosted Grafana installation

AWS EC2 with Amazon Linux 2:
  # Install Grafana on Amazon Linux 2
  sudo yum update -y
  sudo yum install -y wget

  # Download and install Grafana RPM
  wget https://dl.grafana.com/oss/release/grafana-10.x.x-1.x86_64.rpm
  sudo yum localinstall -y grafana-10.x.x-1.x86_64.rpm

  # Start Grafana service
  sudo systemctl start grafana-server
  sudo systemctl enable grafana-server


4. POST-INSTALLATION CONFIGURATION
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Configure Grafana:
  - Edit configuration file (location depends on installation method)
  - Key settings in grafana.ini:
    [server]
    http_port = 3000
    domain = localhost

    [security]
    admin_user = admin
    admin_password = admin

    [database]
    type = sqlite3
    path = grafana.db

    [datasources]
    # Configure Prometheus datasource here or via UI

  - Restart Grafana after configuration changes:
    macOS: brew services restart grafana
    Linux: sudo systemctl restart grafana-server

Add Prometheus as Data Source:
  1. Login to Grafana (http://localhost:3000)
  2. Go to Configuration > Data Sources
  3. Click "Add data source"
  4. Select "Prometheus"
  5. Enter Prometheus URL: http://localhost:9090
  6. Click "Save & Test"

Security Considerations:
  - Change default admin password immediately
  - Configure authentication (LDAP, OAuth, etc.)
  - Use reverse proxy (nginx, Apache) for HTTPS
  - Configure firewall rules
  - Use AWS Security Groups to restrict access
  - Enable SSL/TLS for production


5. VERIFICATION
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Check if Grafana is running:
  macOS: brew services list | grep grafana
  Linux: sudo systemctl status grafana-server
  Docker: docker ps | grep grafana

Test Grafana API:
  curl http://localhost:3000/api/health

Access Grafana UI:
  http://localhost:3000 (or http://<EC2-IP>:3000 for EC2)

Default login:
  Username: admin
  Password: admin (change on first login)


Docker grafana startup guide: https://github.com/aussiearef/grafana-udemy/tree/main/docker

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Things to practice
  - Implement Side Car patern
  - Relabeling K8 values : https://www.youtube.com/watch?v=mXvuKAb6ZwY
  - Use Service discovery with AWS and file basesd Service discovery
  - Use All the available authentication techniques to secure all the components of Promethus (alert manager, exporter, UI, push gateway etc)
  - enable https 
  - application or packages ecuroty and vulnerablity checks or CVE checks
  - learn about  loki, tempo, mimir, pyroscope,beyla, alloy, k6 ,opentelemetry


